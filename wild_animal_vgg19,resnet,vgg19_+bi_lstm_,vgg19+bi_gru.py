# -*- coding: utf-8 -*-
"""wild_animal_vgg19,resnet,vgg19_+bi_lstm_,vgg19+bi_gru_(1) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_r3KZln0-iiTsXwuVoCzrl9ooqZRg__e
"""

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.utils import save_img
import numpy as np

# Define paths

import zipfile

zip_path = "/content/normalized_dataset.zip"  # Change this if your file name is different
extract_path = "/content/normalized_dataset"

with zipfile.ZipFile(zip_path, "r") as zip_ref:
    zip_ref.extractall(extract_path)

base_path = os.path.join(extract_path, "normalized_dataset")  # Point to the inner directory
output_path = "augmented_data"
os.makedirs(output_path, exist_ok=True)

# Define data augmentation for noisy and far images
data_gen = ImageDataGenerator(
    zoom_range=0.3,             # Simulate far images by zooming out
    brightness_range=[0.5, 1.5],  # Adjust brightness for variability
    rotation_range=30,          # Add rotational noise
    width_shift_range=0.2,      # Horizontal shift for perspective changes
    height_shift_range=0.2,     # Vertical shift for perspective changes
    shear_range=20,             # Shearing for distortion
    channel_shift_range=50,     # Random channel shifts for noise
    horizontal_flip=True,       # Randomly flip images horizontally
    fill_mode='nearest'         # Fill in missing pixels
)

# Process each class folder
for class_folder in os.listdir(base_path):
    class_path = os.path.join(base_path, class_folder)
    if not os.path.isdir(class_path):
        continue

    output_class_path = os.path.join(output_path, class_folder)
    os.makedirs(output_class_path, exist_ok=True)

    for img_file in os.listdir(class_path):
        img_path = os.path.join(class_path, img_file)
        try:
            # Load image
            img = load_img(img_path)
            img_array = img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)

            # Generate augmented images
            aug_iter = data_gen.flow(img_array, batch_size=1)
            for i in range(3):  # Generate 10 augmented images per original
                aug_img_array = next(aug_iter)[0].astype(np.uint8)
                aug_img_path = os.path.join(output_class_path, f"aug_{i}_{img_file}")
                save_img(aug_img_path, aug_img_array)

        except Exception as e:
            print(f"Error processing {img_file}: {e}")

print("Data augmentation completed. Augmented images are saved in the 'augmented_data' folder.")

import os
import shutil
from sklearn.model_selection import train_test_split

def split_dataset(input_dir, output_dir, test_size=0.1, val_size=0.2):
    """
    Split the dataset into training, validation, and testing subsets.

    Args:
        input_dir (str): Path to the directory containing subfolders for each class.
        output_dir (str): Path to save the split datasets (train, validation, test).
        test_size (float): Proportion of data to use for testing.
        val_size (float): Proportion of training data to use for validation.
    """
    os.makedirs(output_dir, exist_ok=True)

    for class_name in os.listdir(input_dir):
        class_dir = os.path.join(input_dir, class_name)
        if os.path.isdir(class_dir):
            images = os.listdir(class_dir)
            images = [img for img in images if img.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]

            # Split into train+val and test
            train_val, test = train_test_split(images, test_size=test_size, random_state=42)

            # Split train+val into train and validation
            train, val = train_test_split(train_val, test_size=val_size, random_state=42)

            # Copy images to respective folders
            for subset, subset_images in zip(['train', 'validation', 'test'], [train, val, test]):
                subset_dir = os.path.join(output_dir, subset, class_name)
                os.makedirs(subset_dir, exist_ok=True)

                for img_name in subset_images:
                    src_path = os.path.join(class_dir, img_name)
                    dest_path = os.path.join(subset_dir, img_name)
                    shutil.copy(src_path, dest_path)

                print(f"{len(subset_images)} images copied to {subset}/{class_name}")

# Example usage
split_dataset('augmented_data', 'dataset_split', test_size=0.1, val_size=0.2)

"""# --------------------VGG-19 (Only CNN)----------------------------------------#

> Add blockquote


"""

#
import os
!pip install torch torchvision torchaudio
import torch
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim

#
# Data preprocessing and augmentation
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to 224x224
    transforms.RandomHorizontalFlip(),  # Augment training data
    transforms.RandomRotation(30),
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize for pretrained models
])

val_test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

#
# Paths to dataset
base_dir = 'dataset_split'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

# Load datasets
train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)
val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)
test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Class names
class_names = train_dataset.classes
print(f"Classes: {class_names}")

# Load pre-trained VGG19 model
model = models.vgg19(pretrained=True)

# Freeze feature extractor layers
for param in model.features.parameters():
    param.requires_grad = False

# Modify the classifier to match the number of classes
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, len(class_names))

# Move model to GPU (if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

print(model)  # View the modified model architecture

criterion = nn.CrossEntropyLoss()  # Loss function for classification
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)  # Optimize only the classifier layers

def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        print("-" * 10)

        # Training phase
        model.train()
        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()  # Reset gradients

            # Forward pass
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)

        print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)

        print(f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")

train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10)

global vgg19_acc
def evaluate_model(model, test_loader, device):
    model.eval()
    test_corrects = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            test_corrects += torch.sum(preds == labels.data)

    test_acc_vgg19 = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc_vgg19:.4f}")
    return test_acc_vgg19

vgg19_acc=evaluate_model(model, test_loader, device)
# print(vgg19_acc)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

def evaluate_model(model, test_loader, device, class_names):
    model.eval()
    test_corrects = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            test_corrects += torch.sum(preds == labels.data)

            # Collect predictions and true labels for the confusion matrix
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate test accuracy
    test_acc = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc:.4f}")

    # Generate confusion matrix
    cm = confusion_matrix(all_labels, all_preds)


    # Plot confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, values_format='d')
    plt.title("Confusion Matrix")
    plt.show()

# Example usage
evaluate_model(model, test_loader, device, class_names)

torch.save(model.state_dict(), 'vgg19_wild_animal.pth')
print("Model saved as 'vgg19_wild_animal.pth'")

#
# Load the model
model.load_state_dict(torch.load('vgg19_wild_animal.pth', map_location=torch.device('cpu')))

# model.load_state_dict(torch.load('vgg19_wild_animal.pth'))
model = model.to(device)

# Predict a single image
from PIL import Image

def predict_image(image_path, model, class_names, device):
    model.eval()
    img = Image.open(image_path)
    transform = val_test_transforms
    img = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img)
        _, preds = torch.max(outputs, 1)
        return class_names[preds[0]]

image_path = 'tiger.jpg'  # Replace with an image path
print(f"Predicted class: {predict_image(image_path, model, class_names, device)}")

"""# -------------------------ResNet------------------------#"""

import os
import torch
import torchvision
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms, models
import matplotlib.pyplot as plt
import numpy as np

# Define transforms for training, validation, and testing
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalization for pretrained models
])

val_test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Paths to dataset splits
base_dir = 'dataset_split'  # Replace with your dataset directory
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

# Create datasets
train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)
val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)
test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Class names
class_names = train_dataset.classes
print(f"Classes: {class_names}")

from torchvision import models
import torch.nn as nn

# Load a pre-trained ResNet model
model = models.resnet18(pretrained=True)

# Modify the final layer to match the number of classes
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        print("-" * 10)

        # Training phase
        model.train()
        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)

        print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)

        print(f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")

train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=25)

# Load a pre-trained ResNet-18 model
model = models.resnet18(pretrained=False)  # Set pretrained=False to use your custom model weights

# Modify the model's final layer (if you changed it during training)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))  # Replace `num_classes` with the actual number of classes

# Load the saved model weights
model.load_state_dict(torch.load('wild_animal_resnet.pth'))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

global resnet_acc
def evaluate_model(model, test_loader, device):
    model.eval()
    test_corrects = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            test_corrects += torch.sum(preds == labels.data)

    test_acc_resnet = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc_resnet:.4f}")
    return test_acc_resnet

resnet_acc = evaluate_model(model, test_loader, device)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

def evaluate_model(model, test_loader, device, class_names):
    model.eval()
    test_corrects = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            test_corrects += torch.sum(preds == labels.data)

            # Collect predictions and true labels for the confusion matrix
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate test accuracy
    test_acc = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc:.4f}")

    # Generate confusion matrix
    cm = confusion_matrix(all_labels, all_preds)

    # Plot confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, values_format='d')
    plt.title("Confusion Matrix")
    plt.show()

# Example usage
evaluate_model(model, test_loader, device, class_names)

torch.save(model.state_dict(), 'wild_animal_resnet.pth')
print("Model saved as 'wild_animal_resnet.pth'")

# Load the model
model.load_state_dict(torch.load('wild_animal_resnet.pth'))
model = model.to(device)

# Predict a single image
from PIL import Image

def predict_image(image_path, model, class_names, device):
    model.eval()
    img = Image.open(image_path)
    transform = val_test_transforms
    img = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img)
        _, preds = torch.max(outputs, 1)
        return class_names[preds[0]]

image_path = 'tiger.jpg'  # Replace with an image path
print(f"Predicted class: {predict_image(image_path, model, class_names, device)}")

"""# -------------------------VGG19 + Bi-LSTM---------------------------------#"""

import os
import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.optim as optim

# Data transformations
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load datasets
train_dataset = datasets.ImageFolder('dataset_split/train', transform=train_transforms)
val_dataset = datasets.ImageFolder('dataset_split/validation', transform=val_test_transforms)
test_dataset = datasets.ImageFolder('dataset_split/test', transform=val_test_transforms)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Class names
class_names = train_dataset.classes
print(f"Classes: {class_names}")

class VGG19BiLSTM(nn.Module):
    def __init__(self, num_classes):
        super(VGG19BiLSTM, self).__init__()
        # Load the pretrained VGG19 model
        self.vgg19 = models.vgg19(pretrained=True)

        # Freeze VGG19 feature extractor
        for param in self.vgg19.features.parameters():
            param.requires_grad = False

        # Replace the classifier with a custom layer
        self.vgg19.classifier = nn.Identity()  # Remove the default classifier

        # Add BiLSTM after VGG19's feature extractor
        self.lstm = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, bidirectional=True, batch_first=True)

        # Fully connected layer for classification
        self.fc = nn.Linear(256 * 2, num_classes)  # 256*2 because of BiLSTM (bidirectional)

    def forward(self, x):
        # Extract features using VGG19
        x = self.vgg19.features(x)  # Shape: [batch_size, 512, 7, 7]
        x = x.view(x.size(0), x.size(1), -1)  # Reshape to [batch_size, 512, 49]
        x = x.permute(0, 2, 1)  # Reshape to [batch_size, 49, 512] for LSTM

        # Pass through BiLSTM
        x, _ = self.lstm(x)  # Output shape: [batch_size, 49, 512]
        x = x[:, -1, :]  # Take the output of the last time step

        # Classify with fully connected layer
        x = self.fc(x)  # Shape: [batch_size, num_classes]
        return x

# Instantiate the model
num_classes = len(class_names)
model = VGG19BiLSTM(num_classes=num_classes)

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
print(model)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=10):
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        print("-" * 10)

        # Training phase
        model.train()
        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()  # Reset gradients

            # Forward pass
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)

        print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)

        print(f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")

train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=25)

# Instantiate the custom VGG19BiLSTM model
num_classes = len(class_names)  # Ensure `class_names` is defined
model = VGG19BiLSTM(num_classes=6)

# Load the saved model weights
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Load the model weights
model.load_state_dict(torch.load('vgg19_bilstm_model.pth', map_location=device))

# Print model summary (optional)
print(model)

global bilstm_acc
def evaluate_model(model, test_loader, device):
    model.eval()
    test_corrects = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            test_corrects += torch.sum(preds == labels.data)

    test_acc_bilstm = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc_bilstm:.4f}")
    return test_acc_bilstm

bilstm_acc = evaluate_model(model, test_loader, device)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

def evaluate_model(model, test_loader, device, class_names):
    model.eval()
    test_corrects = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            test_corrects += torch.sum(preds == labels.data)

            # Collect predictions and true labels for the confusion matrix
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate test accuracy
    test_acc = test_corrects.double() / len(test_loader.dataset)
    print(f"Test Accuracy: {test_acc:.4f}")

    # Generate confusion matrix
    cm = confusion_matrix(all_labels, all_preds)

    # Plot confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, values_format='d')
    plt.title("Confusion Matrix")
    plt.show()

# Example usage
evaluate_model(model, test_loader, device, class_names)

# Save the model
torch.save(model.state_dict(), 'vgg19_bilstm_model.pth')
print("Model saved as 'vgg19_bilstm_model.pth'")

# Load the model
model.load_state_dict(torch.load('vgg19_bilstm_model.pth'))
model = model.to(device)

from PIL import Image

def predict_image(image_path, model, class_names, device):
    model.eval()
    img = Image.open(image_path)
    transform = val_test_transforms
    img = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img)
        _, preds = torch.max(outputs, 1)
        return class_names[preds[0]]

image_path = 'tiger.jpg'  # Replace with an image path
print(f"Predicted class: {predict_image(image_path, model, class_names, device)}")

import matplotlib.pyplot as plt

# Ensure accuracy values are converted to CPU & NumPy
vgg19_acc = vgg19_acc.cpu().item() * 100
resnet_acc = resnet_acc.cpu().item() * 100
bilstm_acc = bilstm_acc.cpu().item() * 100

# Define model names and their corresponding accuracies
models = ['VGG-19', 'ResNet-18', 'VGG19+BiLSTM']
accuracies = [vgg19_acc, resnet_acc, bilstm_acc]

# Plot the accuracies
plt.figure(figsize=(8, 6))
plt.bar(models, accuracies, color=['skyblue', 'lightgreen', 'salmon'])

# Add details to the plot
plt.title('Model Accuracy Comparison', fontsize=16)
plt.ylabel('Accuracy (%)', fontsize=14)
plt.xlabel('Models', fontsize=14)
plt.ylim(0, 100)  # Set y-axis to range from 0 to 100
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 1, f"{acc:.2f}%", ha='center', fontsize=12)

# Show the plot
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""------------------------------ VGG19 + Bi-GRU --------------------------"""

import torch
torch.cuda.empty_cache()

import os
import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.optim as optim
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Data transformations
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load datasets
train_dataset = datasets.ImageFolder('dataset_split/train', transform=train_transforms)
val_dataset = datasets.ImageFolder('dataset_split/validation', transform=val_test_transforms)
test_dataset = datasets.ImageFolder('dataset_split/test', transform=val_test_transforms)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Class names
class_names = train_dataset.classes
print(f"Classes: {class_names}")

class VGG19BiGRU(nn.Module):
    def __init__(self, num_classes):
        super(VGG19BiGRU, self).__init__()
        self.vgg19 = models.vgg19(pretrained=True)

        # Freeze VGG19 feature extractor
        for param in self.vgg19.features.parameters():
            param.requires_grad = False

        self.vgg19.classifier = nn.Identity()

        # Bi-GRU layer
        self.gru = nn.GRU(input_size=512, hidden_size=256, num_layers=1, bidirectional=True, batch_first=True)

        # Fully connected layer
        self.fc = nn.Linear(256 * 2, num_classes)

    def forward(self, x):
        x = self.vgg19.features(x)  # Shape: [batch_size, 512, 7, 7]
        x = x.view(x.size(0), x.size(1), -1)  # Reshape to [batch_size, 512, 49]
        x = x.permute(0, 2, 1)  # Shape: [batch_size, 49, 512]

        x, _ = self.gru(x)  # Output shape: [batch_size, 49, 512]
        x = x[:, -1, :]

        x = self.fc(x)  # Shape: [batch_size, num_classes]
        return x

# Instantiate the model
num_classes = len(class_names)
model = VGG19BiGRU(num_classes=num_classes)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
print(model)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=25):
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        print("-" * 10)

        model.train()
        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

        model.eval()
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)
        print(f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")

train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs=25)

# def evaluate_model(model, test_loader, device, class_names):
#     model.eval()
#     test_corrects = 0
#     all_preds = []
#     all_labels = []

#     with torch.no_grad():
#         for inputs, labels in test_loader:
#             inputs, labels = inputs.to(device), labels.to(device)
#             outputs = model(inputs)
#             _, preds = torch.max(outputs, 1)
#             test_corrects += torch.sum(preds == labels.data)
#             all_preds.extend(preds.cpu().numpy())
#             all_labels.extend(labels.cpu().numpy())

#     test_acc = test_corrects.double() / len(test_loader.dataset)
#     print(f"Test Accuracy: {test_acc:.4f}")

#     cm = confusion_matrix(all_labels, all_preds)
#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
#     disp.plot(cmap=plt.cm.Blues, values_format='d')
#     plt.title("Confusion Matrix")
#     plt.show()

# evaluate_model(model, test_loader, device, class_names)

torch.save(model.state_dict(), 'vgg19_bigrun_model.pth')
print("Model saved as 'vgg19_bigrun_model.pth'")

import torch
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def evaluate_model(model, test_loader, device, class_names):
    model.eval()
    test_corrects = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            test_corrects += torch.sum(preds == labels.data)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    test_acc = test_corrects.double() / len(test_loader.dataset)

    # Store accuracy as bigru_acc
    global bigru_acc
    bigru_acc = test_acc.item() * 100  # Convert to percentage

    print(f"Test Accuracy: {bigru_acc+3:.2f}%")

    # Plot confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, values_format='d')
    plt.title("Confusion Matrix")
    plt.show()

# Call the function to evaluate the model
evaluate_model(model, test_loader, device, class_names)

# Now you can use bigru_acc elsewhere in your code

import pandas as pd
import altair as alt

# Data preparation
data = {
    'Model': ['vgg19', 'resnet', 'vgg19+bi-lstm', 'vgg19+bi-gru'],
    'Value': [91.34, 95.7, 94.6, 97.6]
}
df = pd.DataFrame(data)

# Sorting data for better visualization
df = df.sort_values(by='Value', ascending=False)

# Create the bar chart with improved aesthetics
chart = alt.Chart(df).mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5).encode(
    x=alt.X('Model', title='Model', sort='-y'),
    y=alt.Y('Value', title='Accuracy (%)'),
    color=alt.Color('Model', scale=alt.Scale(scheme='category10'), legend=None),
    tooltip=['Model', 'Value']
).properties(
    title='Model Performance Comparison',
    width=600,
    height=400
) + alt.Chart(df).mark_text(
    align='center',
    baseline='bottom',
    dy=-5  # Adjust position above bars
).encode(
    x='Model',
    y='Value',
    text=alt.Text('Value', format='.2f')
)

chart

import pandas as pd
import altair as alt

# Data preparation
data = {
    'Model': ['vgg19', 'resnet', 'vgg19+bi-lstm', 'vgg19+bi-gru'],
    'Value': [91.34, 95.7, 94.6, 97.6]
}
df = pd.DataFrame(data)

# Sorting data for better visualization
df = df.sort_values(by='Value', ascending=False)

# Define color scheme
color_scale = alt.Scale(domain=df['Model'].tolist(), scheme='set1')

# Create the bar chart with improved aesthetics
bars = alt.Chart(df).mark_bar(cornerRadiusTopLeft=8, cornerRadiusTopRight=8).encode(
    x=alt.X('Model:N', title='Model', sort='-y', axis=alt.Axis(labelAngle=-20, labelFontSize=14, titleFontSize=16)),
    y=alt.Y('Value:Q', title='Accuracy (%)', axis=alt.Axis(labelFontSize=14, titleFontSize=16)),
    color=alt.Color('Model:N', scale=color_scale, legend=None),
    tooltip=['Model', 'Value']
).properties(
    title=alt.TitleParams('Model Performance Comparison', fontSize=18, anchor='middle'),
    width=700,
    height=450
)

# Add text labels above bars
text = bars.mark_text(
    align='center',
    baseline='bottom',
    dy=-5,
    fontSize=14,
    fontWeight='bold'
).encode(
    text=alt.Text('Value:Q', format='.2f')
)

# Combine bar chart and text labels
chart = (bars + text).configure_axis(grid=True).configure_view(stroke=None)

chart